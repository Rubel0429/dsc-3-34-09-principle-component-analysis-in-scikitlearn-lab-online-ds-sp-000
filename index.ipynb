{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pincipal Component Analysis in scikit-learn - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "PCA algorithm is generally applied in dimension reduction contexts with an option to visualize a complex high dimensional dataset in 2D or 3D. PCA can also do an amazing job towards removing the computational cost of other machine learning algorithms by allowing them to train on a reduced set of features (principal components)\n",
    "In this lesson, we shall look into implementing PCA with `scikit-learn` to the popular iris dataset, in an attempt to reduce the number of dimensions from 4 to 2 and see if the reduced set of dimensions would still preserve the variance of complete dataset. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Perform PCA in Python and scikit-learn using Iris dataset\n",
    "- Measure the impact of PCA on the accuracy of classification algorithms\n",
    "- Plot the decision boundary of different classification experiments to visually inspect their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset\n",
    "\n",
    "In this post we'll see how to use Principal Component Analysis to perform linear data reduction for the purpose of data visualization. Let's load the necessary libraries and iris dataset to get us started. \n",
    "\n",
    "Perform following steps:\n",
    "\n",
    "- Load Iris dataset into a pandas data frame  from the source \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\". (You can use `read_scv()` to load it directly from the server. \n",
    "- Give appropriate column names to dataset\n",
    "- View the contents of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "1           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "2           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "3           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "4           5.4          3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\")\n",
    "iris.columns = columns\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we see a set of four input features i.e. four dimensions. Our goal for this simple analysis is to reduce this number to 2 (or 3) so that we can visualize the resulting principal components using the standard plotting techniques that we have learned so far in the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that PCA creates a feature __subspace__ that maximizes the variance along the axes. As features could belong to different scales of measurement, our first step in PCA is __always__ to standardize the feature set. Although, all features in the Iris dataset were measured on a same scale (i.e. cm), we shall still perform this step to get a mean=0 and variance=1 as a \"standard practice\". This helps PCA and a number of other machine learning algorithms to perform optimally. Visit [Importance of feature scaling](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py) at sk-learn documentation to read more on this. \n",
    "\n",
    "Let's create our feature and target datasets first.\n",
    "- Create a set of features with 'sepal length', 'sepal width', 'petal length', 'petal width'. \n",
    "- Create X and y datasets based on features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(['species'], axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take our feature set `X`  and standardize it using `StandardScalar` method from sk-learn. \n",
    "- Standardize the feature set X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.148356</td>\n",
       "      <td>-0.118060</td>\n",
       "      <td>-1.353964</td>\n",
       "      <td>-1.325063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.390542</td>\n",
       "      <td>0.344859</td>\n",
       "      <td>-1.410986</td>\n",
       "      <td>-1.325063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.511636</td>\n",
       "      <td>0.113399</td>\n",
       "      <td>-1.296943</td>\n",
       "      <td>-1.325063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.027262</td>\n",
       "      <td>1.270695</td>\n",
       "      <td>-1.353964</td>\n",
       "      <td>-1.325063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.542889</td>\n",
       "      <td>1.965072</td>\n",
       "      <td>-1.182901</td>\n",
       "      <td>-1.061466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0     -1.148356    -0.118060     -1.353964    -1.325063\n",
       "1     -1.390542     0.344859     -1.410986    -1.325063\n",
       "2     -1.511636     0.113399     -1.296943    -1.325063\n",
       "3     -1.027262     1.270695     -1.353964    -1.325063\n",
       "4     -0.542889     1.965072     -1.182901    -1.061466"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data = X, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Projection to 2D Space\n",
    "\n",
    "We shall now project the original data which is 4 dimensional into 2 dimensions. Remember,  there usually isn’t a particular meaning assigned to each principal component. The new components are just the two main dimensions of variance present in the data. To perform `PCA` with sk-learn, we need to import it first and create an instance of PCA while defining the number of principal components. \n",
    "\n",
    "- Initialize an instance of PCA from scikit-learn with 2 components\n",
    "- Fit the data to the model\n",
    "- Extract the first 2 principal components from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52308496 -0.25956935  0.58184289  0.56609604]\n",
      " [ 0.36956962  0.92681168  0.01912775  0.06381646]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(X)\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can now save the results in a new dataframe and name the columns according the first/second component. \n",
    "\n",
    "- Append the target (flower name) to the principal components in a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.107950</td>\n",
       "      <td>-0.644276</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.387971</td>\n",
       "      <td>-0.305833</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.324879</td>\n",
       "      <td>-0.562923</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.405086</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.083204</td>\n",
       "      <td>1.530252</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2      species\n",
       "0 -2.107950 -0.644276  Iris-setosa\n",
       "1 -2.387971 -0.305833  Iris-setosa\n",
       "2 -2.324879 -0.562923  Iris-setosa\n",
       "3 -2.405086  0.687591  Iris-setosa\n",
       "4 -2.083204  1.530252  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = data, columns = ['PC1', 'PC2'])\n",
    "new_df = pd.concat([df, iris[['species']]], axis = 1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have a set of two dimensions, reduced from four against our target variable, the flower name. Let's now try to visualize this dataset and see if the different flower species remain separable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Principal Components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the target data, we can visualize the principal components according to the class distribution. \n",
    "- Create a scatter plot from principal components while color coding the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['b', 'g', 'y']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    \n",
    "    indicesToKeep = iris['species'] == target\n",
    "    plt.scatter(new_df.loc[indicesToKeep, 'PC1'], new_df.loc[indicesToKeep, 'PC2'], c = color)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance\n",
    "\n",
    "> __The explained variance tells us how much information (variance) can be attributed to each of the principal components__\n",
    "\n",
    "We can see above that the three classes in the dataset remain well separable. iris-virginica and iris-versicolor could be better separated, but we have to remember that we just reduced the size of dimensions to half. the cost-performance trade-off is something that data scientists often have to come across. In order to get a better idea around how much variance of the original dataset is explained in principal components, we can use the attribute `explained_variance_ratio_`.\n",
    "\n",
    "- Check the explained variance of the two principal components using `explained_variance_ratio_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72620033 0.23147407]\n",
      "\n",
      " 0.9576744018556446\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print('\\n', sum(list(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two PCs contain 95.80% of the information. The first PC contains 72.77% of the variance and the second PC contains 23.03% of the variance. The third and fourth principal component contained the rest of the variance of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance of an Classifier with PCA\n",
    "\n",
    "So our principal components above explained 95% of variance in the data. How much would it effect the accuracy of a classifier? The best way to answer this is with a simple classifier like `KNeighborsClassifier`. We can try to classify this dataset in its original form vs. principal components computed above. \n",
    "\n",
    "- Run a `KNeighborsClassifier` to classify the Iris dataset \n",
    "- Use a trai/test split of 80/20\n",
    "- For reproducability of results, set random state =9 for the split\n",
    "- Time the process for splitting, training and making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "Time Taken: 0.003277539999999135\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import timeit\n",
    "\n",
    "\n",
    "X = iris.drop('species', axis=1)\n",
    "y = iris['species']\n",
    "y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "start = timeit.timeit()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "Yhat = model.predict(X_test)\n",
    "acc = metrics.accuracy_score(Yhat, Y_test)\n",
    "end = timeit.timeit()\n",
    "print(\"Accuracy:\",acc)\n",
    "print (\"Time Taken:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great , so we see that we are able to classify the data with 100% accuracy in the given time. Remember the time taken may different randomly based on the load on your cpu and number of processes running on your PC. \n",
    "\n",
    "Now let's repeat the above process for dataset made from principal components \n",
    "- Run a `KNeighborsClassifier` to classify the Iris dataset with principal components\n",
    "- Use a trai/test split of 80/20\n",
    "- For reproducability of results, set random state =9 for the split\n",
    "- Time the process for splitting, training and making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Time Taken: 0.006670974000030583\n"
     ]
    }
   ],
   "source": [
    "X = new_df[['PC1', 'PC2']]\n",
    "y = iris['species']\n",
    "y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "start = timeit.timeit()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "Yhat = model.predict(X_test)\n",
    "acc = metrics.accuracy_score(Yhat, Y_test)\n",
    "end = timeit.timeit()\n",
    "print(\"Accuracy:\",acc)\n",
    "print (\"Time Taken:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that going from 4 actual dimensions to two derived dimensions. We manage to get an accuracy of 96%. There is some loss but considering big data domain with data possibly having thousands of features, this trade-off is often accepted in order to simplify and speed up computation. The time taken to run the classifer is much less than what we saw with complete dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : Visualize Decision Boundary \n",
    "\n",
    "visualizing decision boundary is good way to develop the intuition around a classifier's performance with 2/3 dimensional data. We can do this often to point out the examples that may not get classified correctly. It also helps us get an insight into how a certain algorithm draws these boundaries i.e. the learning process of an algorithm. \n",
    "\n",
    "- Draw the decision boundary for the classification with principal components (Optional - with complete dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundary using principal components \n",
    "\n",
    "\n",
    "# Your code here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional \n",
    "\n",
    "- Use following classifier instead of KNN shown above to see how much PCA effects the accuracy, coming from 4 to 2 dimensions. \n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "```\n",
    "\n",
    "- Use 3 principal components instead of two and re-run your experiment to see the impact on the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lab we applied PCA to the popular Iris dataset. We looked at performance of a simple classifier and impact of PCA on it. NExt we shall take PCA to a more specialized domain i.e. Computer Vision and Image Processing and see how this technique can be used to image classification and data compression tasks. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
